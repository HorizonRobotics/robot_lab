base_lmdb_dataset
=================

.. py:module:: robo_orchard_lab.dataset.lmdb.base_lmdb_dataset


Attributes
----------

.. autoapisummary::

   robo_orchard_lab.dataset.lmdb.base_lmdb_dataset.logger


Classes
-------

.. autoapisummary::

   robo_orchard_lab.dataset.lmdb.base_lmdb_dataset.BaseIndexData
   robo_orchard_lab.dataset.lmdb.base_lmdb_dataset.BaseLmdbManipulationDataset
   robo_orchard_lab.dataset.lmdb.base_lmdb_dataset.BaseLmdbManipulationDataPacker


Module Contents
---------------

.. py:data:: logger

.. py:class:: BaseIndexData(/, **data: Any)

   Bases: :py:obj:`pydantic.BaseModel`


   Base data structure for indexing simulation or task-related information.


   .. py:attribute:: uuid
      :type:  str


   .. py:attribute:: task_name
      :type:  str


   .. py:attribute:: num_steps
      :type:  int


   .. py:attribute:: user
      :type:  Optional[str]
      :value: None



   .. py:attribute:: embodiment
      :type:  Optional[str]
      :value: None



   .. py:attribute:: date
      :type:  Optional[str]
      :value: None



   .. py:attribute:: simulation
      :type:  bool
      :value: False



   .. py:attribute:: model_config

      Configuration for the model, should be a dictionary conforming to [`ConfigDict`][pydantic.config.ConfigDict].


   .. py:attribute:: model_fields
      :type:  ClassVar[dict[str, pydantic.fields.FieldInfo]]


   .. py:property:: model_extra
      :type: dict[str, Any] | None


      Get extra fields set during validation.

      :returns: A dictionary of extra fields, or `None` if `config.extra` is not set to `"allow"`.


   .. py:property:: model_fields_set
      :type: set[str]


      Returns the set of fields that have been explicitly set on this model instance.

      :returns:

                A set of strings representing the fields that have been set,
                    i.e. that were not filled from defaults.


   .. py:method:: model_construct(_fields_set: set[str] | None = None, **values: Any) -> typing_extensions.Self
      :classmethod:


      Creates a new instance of the `Model` class with validated data.

      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.
      Default values are respected, but no other validation is performed.

      !!! note
          `model_construct()` generally respects the `model_config.extra` setting on the provided model.
          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`
          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.
          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in
          an error if extra values are passed, but they will be ignored.

      :param _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,
                          this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.
                          Otherwise, the field names from the `values` argument will be used.
      :param values: Trusted or pre-validated data dictionary.

      :returns: A new instance of the `Model` class with validated data.



   .. py:method:: model_copy(*, update: Mapping[str, Any] | None = None, deep: bool = False) -> typing_extensions.Self

      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#model_copy

      Returns a copy of the model.

      :param update: Values to change/add in the new model. Note: the data is not validated
                     before creating the new model. You should trust this data.
      :param deep: Set to `True` to make a deep copy of the model.

      :returns: New model instance.



   .. py:method:: model_dump(*, mode: Literal['json', 'python'] | str = 'python', include: IncEx | None = None, exclude: IncEx | None = None, context: Any | None = None, by_alias: bool = False, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, round_trip: bool = False, warnings: bool | Literal['none', 'warn', 'error'] = True, serialize_as_any: bool = False) -> dict[str, Any]

      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump

      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.

      :param mode: The mode in which `to_python` should run.
                   If mode is 'json', the output will only contain JSON serializable types.
                   If mode is 'python', the output may contain non-JSON-serializable Python objects.
      :param include: A set of fields to include in the output.
      :param exclude: A set of fields to exclude from the output.
      :param context: Additional context to pass to the serializer.
      :param by_alias: Whether to use the field's alias in the dictionary key if defined.
      :param exclude_unset: Whether to exclude fields that have not been explicitly set.
      :param exclude_defaults: Whether to exclude fields that are set to their default value.
      :param exclude_none: Whether to exclude fields that have a value of `None`.
      :param round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
      :param warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
                       "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
      :param serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.

      :returns: A dictionary representation of the model.



   .. py:method:: model_dump_json(*, indent: int | None = None, include: IncEx | None = None, exclude: IncEx | None = None, context: Any | None = None, by_alias: bool = False, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, round_trip: bool = False, warnings: bool | Literal['none', 'warn', 'error'] = True, serialize_as_any: bool = False) -> str

      Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump_json

      Generates a JSON representation of the model using Pydantic's `to_json` method.

      :param indent: Indentation to use in the JSON output. If None is passed, the output will be compact.
      :param include: Field(s) to include in the JSON output.
      :param exclude: Field(s) to exclude from the JSON output.
      :param context: Additional context to pass to the serializer.
      :param by_alias: Whether to serialize using field aliases.
      :param exclude_unset: Whether to exclude fields that have not been explicitly set.
      :param exclude_defaults: Whether to exclude fields that are set to their default value.
      :param exclude_none: Whether to exclude fields that have a value of `None`.
      :param round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].
      :param warnings: How to handle serialization errors. False/"none" ignores them, True/"warn" logs errors,
                       "error" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].
      :param serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.

      :returns: A JSON string representation of the model.



   .. py:method:: model_json_schema(by_alias: bool = True, ref_template: str = DEFAULT_REF_TEMPLATE, schema_generator: type[pydantic.json_schema.GenerateJsonSchema] = GenerateJsonSchema, mode: pydantic.json_schema.JsonSchemaMode = 'validation') -> dict[str, Any]
      :classmethod:


      Generates a JSON schema for a model class.

      :param by_alias: Whether to use attribute aliases or not.
      :param ref_template: The reference template.
      :param schema_generator: To override the logic used to generate the JSON schema, as a subclass of
                               `GenerateJsonSchema` with your desired modifications
      :param mode: The mode in which to generate the schema.

      :returns: The JSON schema for the given model class.



   .. py:method:: model_parametrized_name(params: tuple[type[Any], Ellipsis]) -> str
      :classmethod:


      Compute the class name for parametrizations of generic classes.

      This method can be overridden to achieve a custom naming scheme for generic BaseModels.

      :param params: Tuple of types of the class. Given a generic class
                     `Model` with 2 type variables and a concrete model `Model[str, int]`,
                     the value `(str, int)` would be passed to `params`.

      :returns: String representing the new class where `params` are passed to `cls` as type variables.

      :raises TypeError: Raised when trying to generate concrete names for non-generic models.



   .. py:method:: model_post_init(__context: Any) -> None

      Override this method to perform additional initialization after `__init__` and `model_construct`.
      This is useful if you want to do some validation that requires the entire model to be initialized.



   .. py:method:: model_rebuild(*, force: bool = False, raise_errors: bool = True, _parent_namespace_depth: int = 2, _types_namespace: pydantic._internal._namespace_utils.MappingNamespace | None = None) -> bool | None
      :classmethod:


      Try to rebuild the pydantic-core schema for the model.

      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during
      the initial attempt to build the schema, and automatic rebuilding fails.

      :param force: Whether to force the rebuilding of the model schema, defaults to `False`.
      :param raise_errors: Whether to raise errors, defaults to `True`.
      :param _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.
      :param _types_namespace: The types namespace, defaults to `None`.

      :returns: Returns `None` if the schema is already "complete" and rebuilding was not required.
                If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.



   .. py:method:: model_validate(obj: Any, *, strict: bool | None = None, from_attributes: bool | None = None, context: Any | None = None) -> typing_extensions.Self
      :classmethod:


      Validate a pydantic model instance.

      :param obj: The object to validate.
      :param strict: Whether to enforce types strictly.
      :param from_attributes: Whether to extract data from object attributes.
      :param context: Additional context to pass to the validator.

      :raises ValidationError: If the object could not be validated.

      :returns: The validated model instance.



   .. py:method:: model_validate_json(json_data: str | bytes | bytearray, *, strict: bool | None = None, context: Any | None = None) -> typing_extensions.Self
      :classmethod:


      Usage docs: https://docs.pydantic.dev/2.10/concepts/json/#json-parsing

      Validate the given JSON data against the Pydantic model.

      :param json_data: The JSON data to validate.
      :param strict: Whether to enforce types strictly.
      :param context: Extra variables to pass to the validator.

      :returns: The validated Pydantic model.

      :raises ValidationError: If `json_data` is not a JSON string or the object could not be validated.



   .. py:method:: model_validate_strings(obj: Any, *, strict: bool | None = None, context: Any | None = None) -> typing_extensions.Self
      :classmethod:


      Validate the given object with string data against the Pydantic model.

      :param obj: The object containing string data to validate.
      :param strict: Whether to enforce types strictly.
      :param context: Extra variables to pass to the validator.

      :returns: The validated Pydantic model.



   .. py:method:: dict(*, include: IncEx | None = None, exclude: IncEx | None = None, by_alias: bool = False, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False) -> Dict[str, Any]


   .. py:method:: json(*, include: IncEx | None = None, exclude: IncEx | None = None, by_alias: bool = False, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Callable[[Any], Any] | None = PydanticUndefined, models_as_dict: bool = PydanticUndefined, **dumps_kwargs: Any) -> str


   .. py:method:: parse_obj(obj: Any) -> typing_extensions.Self
      :classmethod:



   .. py:method:: parse_raw(b: str | bytes, *, content_type: str | None = None, encoding: str = 'utf8', proto: pydantic.deprecated.parse.Protocol | None = None, allow_pickle: bool = False) -> typing_extensions.Self
      :classmethod:



   .. py:method:: parse_file(path: str | pathlib.Path, *, content_type: str | None = None, encoding: str = 'utf8', proto: pydantic.deprecated.parse.Protocol | None = None, allow_pickle: bool = False) -> typing_extensions.Self
      :classmethod:



   .. py:method:: from_orm(obj: Any) -> typing_extensions.Self
      :classmethod:



   .. py:method:: construct(_fields_set: set[str] | None = None, **values: Any) -> typing_extensions.Self
      :classmethod:



   .. py:method:: copy(*, include: pydantic._internal._utils.AbstractSetIntStr | pydantic._internal._utils.MappingIntStrAny | None = None, exclude: pydantic._internal._utils.AbstractSetIntStr | pydantic._internal._utils.MappingIntStrAny | None = None, update: Dict[str, Any] | None = None, deep: bool = False) -> typing_extensions.Self

      Returns a copy of the model.

      !!! warning "Deprecated"
          This method is now deprecated; use `model_copy` instead.

      If you need `include` or `exclude`, use:

      ```python {test="skip" lint="skip"}
      data = self.model_dump(include=include, exclude=exclude, round_trip=True)
      data = {**data, **(update or {})}
      copied = self.model_validate(data)
      ```

      :param include: Optional set or mapping specifying which fields to include in the copied model.
      :param exclude: Optional set or mapping specifying which fields to exclude in the copied model.
      :param update: Optional dictionary of field-value pairs to override field values in the copied model.
      :param deep: If True, the values of fields that are Pydantic models will be deep-copied.

      :returns: A copy of the model with included, excluded and updated fields as specified.



   .. py:method:: schema(by_alias: bool = True, ref_template: str = DEFAULT_REF_TEMPLATE) -> Dict[str, Any]
      :classmethod:



   .. py:method:: schema_json(*, by_alias: bool = True, ref_template: str = DEFAULT_REF_TEMPLATE, **dumps_kwargs: Any) -> str
      :classmethod:



   .. py:method:: validate(value: Any) -> typing_extensions.Self
      :classmethod:



   .. py:method:: update_forward_refs(**localns: Any) -> None
      :classmethod:



.. py:class:: BaseLmdbManipulationDataset(paths: Union[str, List[str]], transforms: Optional[List[Callable]] = None, interval: Optional[int] = None, load_image: bool = True, load_depth: bool = True, task_names: Optional[Union[str, List[str]]] = None, num_episode: Optional[int] = None, lazy_init: bool = False, encoding_mode: str = 'utf-8')

   Bases: :py:obj:`torch.utils.data.Dataset`


   A dataset class for manipulation tasks stored in LMDB format.

   The dataset is structured into four fundamental components:
   `index`, `meta`, `depth`, and `image`.

   .. note::

       **index** and **meta** are organized by episode as the basic unit.

       **depth** and **image** are stored by frame as the basic unit.

   An example:

   .. code-block:: text

       - index:
           - `episode_id`: `BaseIndexData`.
       - meta:
           - `{uuid}/meta_data`: General metadata about the task.
           - `{uuid}/camera_names`: List of camera names used in the task.
           - `{uuid}/observation/joint_positions`: [num_steps * num_joint]
       - image:
           - `{uuid}/{cam_name}/{step_idx}`: image_buffer
       - depth:
           - `{uuid}/{cam_name}/{step_idx}`: depth_buffer

   :param paths: Path(s) to the LMDB database(s). Can be
                 a single path or a list of paths.
   :type paths: Union[str, List[str]]
   :param transforms: A function/transform to apply to
                      the data samples. Can also be a sequence of transforms.
                      Default: None.
   :type transforms: Optional[List[Callable]]
   :param interval: Interval between steps to sample.
                    Default: None
   :type interval: Optional[int]
   :param load_image: Whether to load image data. Default: True.
   :type load_image: bool
   :param load_depth: Whether to load depth data. Default: True.
   :type load_depth: bool
   :param task_names: List of task names to
                      filter by. Default: None.
   :type task_names: Optional[Union[str, List[str]]]
   :param num_episode: Maximum number of episodes to load.
                       Default: None.
   :type num_episode: Optional[int]
   :param lazy_init: If True, initialization is deferred until first
                     access. Default: False.
   :type lazy_init: bool
   :param encoding_mode: Encoding mode of keys from LMDB.
                         Default: "utf-8".
   :type encoding_mode: str


   .. py:attribute:: paths


   .. py:attribute:: transforms
      :value: []



   .. py:attribute:: interval
      :value: None



   .. py:attribute:: load_image
      :value: True



   .. py:attribute:: load_depth
      :value: True



   .. py:attribute:: task_names
      :value: None



   .. py:attribute:: num_episode_
      :value: None



   .. py:attribute:: encoding_mode
      :value: 'utf-8'



   .. py:attribute:: initialized
      :value: False



   .. py:method:: visualize(episode_index, output_path='./vis_data')
      :abstractmethod:



.. py:class:: BaseLmdbManipulationDataPacker(input_path, output_path, commit_step=500, **kwargs)

   Bases: :py:obj:`object`


   .. py:attribute:: input_path


   .. py:attribute:: output_path


   .. py:attribute:: commit_step
      :value: 500



   .. py:attribute:: lmdb_kwargs


   .. py:method:: close()


   .. py:method:: write_index(index: Union[int, str], index_data: dict)


